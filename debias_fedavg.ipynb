{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9998,
     "status": "ok",
     "timestamp": 1717361781982,
     "user": {
      "displayName": "ziyang zhang",
      "userId": "05666835680081696287"
     },
     "user_tz": 300
    },
    "id": "N3NiVjOABVQc"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import random\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3cMHDFPHBeZG",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Dataset Curation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7486,
     "status": "ok",
     "timestamp": 1717361792599,
     "user": {
      "displayName": "ziyang zhang",
      "userId": "05666835680081696287"
     },
     "user_tz": 300
    },
    "id": "kekMfbQEEZMn",
    "outputId": "2502ad03-7a3c-40bc-cde5-b2993ada1d7c"
   },
   "outputs": [],
   "source": [
    "training_data = datasets.MNIST(\n",
    "    root=\"/Users/Downloads/learning_data/\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"/Users/Downloads/learning_data/\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 675
    },
    "executionInfo": {
     "elapsed": 1260,
     "status": "ok",
     "timestamp": 1717361796968,
     "user": {
      "displayName": "ziyang zhang",
      "userId": "05666835680081696287"
     },
     "user_tz": 300
    },
    "id": "ImGcSr4AFXuo",
    "outputId": "64bb08d3-0ad3-4195-d625-d298abf5694f"
   },
   "outputs": [],
   "source": [
    "lables_map = {\n",
    "    0: 'zero',\n",
    "    1: 'one',\n",
    "    2: 'two',\n",
    "    3: 'three',\n",
    "    4: 'four',\n",
    "    5: 'five',\n",
    "    6: 'six',\n",
    "    7: 'seven',\n",
    "    8: 'eight',\n",
    "    9: 'nine',\n",
    "}\n",
    "\n",
    "figure = plt.figure(figsize=(8, 8))\n",
    "cols, rows = 3, 3\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(training_data), size=(1,)).item()\n",
    "    img, label = training_data[sample_idx]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(lables_map[label])\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 203,
     "status": "ok",
     "timestamp": 1717366177225,
     "user": {
      "displayName": "ziyang zhang",
      "userId": "05666835680081696287"
     },
     "user_tz": 300
    },
    "id": "E_jKWm6AG__f"
   },
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "def dirichlet_allocation(dataset, num_clients, alpha=0.5):\n",
    "    class_indices = [np.where(dataset.targets.numpy() == i)[0] for i in range(10)]\n",
    "    client_train_indices = {i: np.array([], dtype=int) for i in range(num_clients)}\n",
    "    client_val_indices = {i: np.array([], dtype=int) for i in range(num_clients)}\n",
    "\n",
    "    for class_idx in class_indices:\n",
    "        split_idx = int(len(class_idx) * 0.8)\n",
    "        train_class_idx = class_idx[:split_idx]\n",
    "        val_class_idx = class_idx[split_idx:]\n",
    "\n",
    "        proportions = np.random.dirichlet([alpha] * num_clients)\n",
    "\n",
    "        train_class_splits = np.array_split(train_class_idx, (proportions.cumsum()[:-1] * len(train_class_idx)).astype(int))\n",
    "        for i, split in enumerate(train_class_splits):\n",
    "            client_train_indices[i] = np.concatenate([client_train_indices[i], split])\n",
    "\n",
    "        val_class_splits = np.array_split(val_class_idx, (proportions.cumsum()[:-1] * len(val_class_idx)).astype(int))\n",
    "        for i, split in enumerate(val_class_splits):\n",
    "            client_val_indices[i] = np.concatenate([client_val_indices[i], split])\n",
    "\n",
    "    client_dataloaders = {}\n",
    "    for i in range(num_clients):\n",
    "        train_dataset = Subset(dataset, client_train_indices[i])\n",
    "        val_dataset = Subset(dataset, client_val_indices[i])\n",
    "        train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True, drop_last=True)\n",
    "        val_dataloader = DataLoader(val_dataset, batch_size=8, shuffle=True, drop_last=True)\n",
    "        client_dataloaders[i] = (train_dataloader, val_dataloader)\n",
    "\n",
    "    return client_dataloaders\n",
    "\n",
    "\n",
    "num_clients = 100\n",
    "allocated_dataloaders = dirichlet_allocation(training_data, num_clients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1717366194083,
     "user": {
      "displayName": "ziyang zhang",
      "userId": "05666835680081696287"
     },
     "user_tz": 300
    },
    "id": "HqUq7H6rHvW2",
    "outputId": "a12b7191-a14f-44ed-ec55-2abbaefc8f15",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for cid, (train_dataloader, val_dataloader) in allocated_dataloaders.items():\n",
    "    print('cid:', cid)\n",
    "    # print(next(iter(train_dataloader))[0].size())\n",
    "    # print(next(iter(val_dataloader))[1].size())\n",
    "    print(len(train_dataloader), len(val_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 121,
     "status": "ok",
     "timestamp": 1717366204526,
     "user": {
      "displayName": "ziyang zhang",
      "userId": "05666835680081696287"
     },
     "user_tz": 300
    },
    "id": "ZRggNbzmqGIA"
   },
   "outputs": [],
   "source": [
    "test_dataloader = DataLoader(test_data, batch_size=len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DXOtYqON-IQ7"
   },
   "source": [
    "# Client Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 124,
     "status": "ok",
     "timestamp": 1717365832118,
     "user": {
      "displayName": "ziyang zhang",
      "userId": "05666835680081696287"
     },
     "user_tz": 300
    },
    "id": "NGhgo264AA0r"
   },
   "outputs": [],
   "source": [
    "class MNISTModel(nn.Module):\n",
    "    def __init__(self, dim_feature):\n",
    "        super(MNISTModel, self).__init__()\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            self.make_linear_block(dim_feature, dim_feature*2),\n",
    "            self.make_linear_block(dim_feature*2, dim_feature//2),\n",
    "            self.make_linear_block(dim_feature//2, 10, is_final_layer=True)\n",
    "        )\n",
    "\n",
    "    def make_linear_block(self, input_channels, output_channels, is_final_layer=False):\n",
    "        if not is_final_layer:\n",
    "            return nn.Sequential(\n",
    "                nn.Linear(input_channels, output_channels),\n",
    "                nn.BatchNorm1d(output_channels),\n",
    "                nn.ReLU()\n",
    "            )\n",
    "        else:\n",
    "            return nn.Sequential(\n",
    "                nn.Linear(input_channels, output_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, img):\n",
    "        img = img.view(-1, 28 * 28)\n",
    "        logits = self.classifier(img)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 107,
     "status": "ok",
     "timestamp": 1717365835363,
     "user": {
      "displayName": "ziyang zhang",
      "userId": "05666835680081696287"
     },
     "user_tz": 300
    },
    "id": "TzQ5d3VICiD2",
    "outputId": "378ddfe4-aa0a-418a-b0a5-a26d4db79b94",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = MNISTModel(28 * 28)\n",
    "parameters = model.state_dict()\n",
    "for key, value in parameters.items():\n",
    "    print(key)\n",
    "    print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 126,
     "status": "ok",
     "timestamp": 1717365840478,
     "user": {
      "displayName": "ziyang zhang",
      "userId": "05666835680081696287"
     },
     "user_tz": 300
    },
    "id": "gfgaY9dfKxJX"
   },
   "outputs": [],
   "source": [
    "def get_accuracy(logits, targets):\n",
    "    prediction = torch.argmax(logits, axis=1)\n",
    "    num_correct = torch.sum(prediction == targets)\n",
    "    accuracy = num_correct / len(targets)\n",
    "    return accuracy.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 128,
     "status": "ok",
     "timestamp": 1717365850160,
     "user": {
      "displayName": "ziyang zhang",
      "userId": "05666835680081696287"
     },
     "user_tz": 300
    },
    "id": "70vXhLnM9ung"
   },
   "outputs": [],
   "source": [
    "class Client:\n",
    "    def __init__(self, dataloaders, cid, device='cpu'):\n",
    "        train_dataloader, val_dataloader = dataloaders\n",
    "        self.train_dataloader = train_dataloader\n",
    "        self.val_dataloader = val_dataloader\n",
    "        self.cid = cid\n",
    "        self.device = device\n",
    "        self.model = MNISTModel(28 * 28).to(self.device)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    def train(self, learning_rate=1e-2, num_epochs=1):\n",
    "        optimizer = optim.SGD(self.model.parameters(), lr=learning_rate)\n",
    "        for epoch in range(num_epochs):\n",
    "            for batch in self.train_dataloader:\n",
    "                imgs, labels = batch\n",
    "                imgs, labels= imgs.to(self.device), labels.to(self.device)\n",
    "                logits = self.model(imgs).to(self.device)\n",
    "                loss = self.criterion(logits, labels)\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "    def evaluate(self):\n",
    "        train_losses = []\n",
    "        all_logits, all_labels = [], []\n",
    "        for batch in self.train_dataloader:\n",
    "            imgs, labels = batch\n",
    "            imgs, labels= imgs.to(self.device), labels.to(self.device)\n",
    "            logits = self.model(imgs).to(self.device)\n",
    "            loss = self.criterion(logits, labels)\n",
    "            train_losses.append(loss.item())\n",
    "            all_logits.append(logits)\n",
    "            all_labels.append(labels)\n",
    "        train_loss = sum(train_losses) / len(train_losses)\n",
    "        all_logits, all_labels = torch.cat(all_logits), torch.concat(all_labels)\n",
    "        train_accuracy = get_accuracy(all_logits.cpu(), all_labels.cpu())\n",
    "\n",
    "        val_losses = []\n",
    "        all_logits, all_labels = [], []\n",
    "        for batch in self.val_dataloader:\n",
    "            imgs, labels = batch\n",
    "            imgs, labels= imgs.to(self.device), labels.to(self.device)\n",
    "            logits = self.model(imgs).to(self.device)\n",
    "            loss = self.criterion(logits, labels)\n",
    "            val_losses.append(loss.item())\n",
    "            all_logits.append(logits)\n",
    "            all_labels.append(labels)\n",
    "        val_loss = sum(val_losses) / len(val_losses)\n",
    "        all_logits, all_labels = torch.cat(all_logits), torch.concat(all_labels)\n",
    "        val_accuracy = get_accuracy(all_logits.cpu(), all_labels.cpu())\n",
    "\n",
    "        return train_loss, train_accuracy, val_loss, val_accuracy\n",
    "\n",
    "    def get_parameters(self):\n",
    "        return self.model.state_dict()\n",
    "\n",
    "    def set_parameters(self, parameters):\n",
    "        self.model.load_state_dict(parameters, strict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8cyGZoBOcY_H"
   },
   "source": [
    "# Server Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 133,
     "status": "ok",
     "timestamp": 1717365851959,
     "user": {
      "displayName": "ziyang zhang",
      "userId": "05666835680081696287"
     },
     "user_tz": 300
    },
    "id": "MpKkuk9taIHr"
   },
   "outputs": [],
   "source": [
    "class Server:\n",
    "    def __init__(self, clients, R=0, M=1, B=1, num_epochs=1, test_dataloader=test_dataloader,\n",
    "                 is_option1=False, is_option2=False, is_fedvarp=False, device='cpu'):\n",
    "        self.test_dataloader = test_dataloader\n",
    "        self.device = device\n",
    "        self.clients = clients\n",
    "        self.num_clients = len(clients)\n",
    "        self.R = R\n",
    "        self.M = M # number of groups\n",
    "        self.B = B # number of clients that participated in local training\n",
    "        self.num_clients_wti_group = self.num_clients // self.M\n",
    "        self.num_epochs = num_epochs\n",
    "        self.server_params = copy.deepcopy(self.clients[0].get_parameters())\n",
    "        self.is_option1 = is_option1\n",
    "        self.is_option2 = is_option2\n",
    "        self.is_fedvarp = is_fedvarp\n",
    "\n",
    "        self.all_groups = {f'idx{i}': self.clients[i:i+self.num_clients_wti_group]\n",
    "                           for i in range(0, self.num_clients, self.num_clients_wti_group)}\n",
    "\n",
    "        if self.is_option1 or self.is_option2 or self.is_fedvarp:\n",
    "            alpha = 1.5\n",
    "            weights = np.array([1.0 / (i+1)**alpha for i in range(self.M)])\n",
    "            heavytail_probabilities = weights / weights.sum()\n",
    "            self.group_probs = {index: heavytail_probabilities[i] for i, (index, _) in enumerate(self.all_groups.items())}\n",
    "        else:\n",
    "            self.group_probs = {index: 1 for i, (index, _) in enumerate(self.all_groups.items())}\n",
    "\n",
    "        self.counts_groups = {index: 0 for index, _ in self.all_groups.items()}\n",
    "        self.y = {index: 0 for index, _ in self.all_groups.items()}\n",
    "        self.q = {index: 0 for index, _ in self.all_groups.items()}\n",
    "\n",
    "        ### variables for fedvarp ###\n",
    "        if self.is_fedvarp:\n",
    "            self.y_for_clients = [self.zero_out_paramters(copy.deepcopy(self.clients[i].get_parameters())) for i in range(self.num_clients)]\n",
    "            self.y_for_server = copy.deepcopy(self.y_for_clients[0])\n",
    "            self.tau = len(clients[0].train_dataloader)\n",
    "\n",
    "    def federated_learning(self, num_rounds=1, lr=1e-2, lr_c=1e-2, lr_s=1):\n",
    "        \n",
    "        last_selected_group_round = {}\n",
    "        li_tl, li_ta, li_vl, li_va = [], [], [], []\n",
    "\n",
    "        for r in range(1, num_rounds + 1):\n",
    "            available_groups = []\n",
    "            for idx, group in self.all_groups.items():\n",
    "                if last_selected_group_round.get(idx, -self.R - 1) < r - self.R:\n",
    "                    available_groups.append((idx, group))\n",
    "\n",
    "            # assign group probs for all of the available groups\n",
    "            li_group_probs_cur = []\n",
    "            for index, group in available_groups:\n",
    "                li_group_probs_cur.append(self.group_probs[index])\n",
    "\n",
    "            selected_idx, selected_group = random.choices(available_groups, weights=li_group_probs_cur, k=1)[0]\n",
    "            if selected_group:\n",
    "                last_selected_group_round[selected_idx] = r\n",
    "            print(f'round {r}', 'selected group:', selected_idx, selected_group)\n",
    "            print()\n",
    "            \n",
    "            # determine learning rate\n",
    "            if self.is_option2:\n",
    "                self.counts_groups[selected_idx] += 1\n",
    "                self.y[selected_idx] = self.counts_groups[selected_idx] / num_rounds\n",
    "                self.q[selected_idx] = 1 / (self.y[selected_idx] * 1)\n",
    "                new_lr = lr * self.q[selected_idx]\n",
    "            elif self.is_fedvarp:\n",
    "                self.lr_c = lr_c\n",
    "                self.lr_s = lr_s\n",
    "                self.lr_s_final = self.lr_c * self.lr_s * self.tau\n",
    "                new_lr = self.lr_c\n",
    "            else:\n",
    "                new_lr = lr\n",
    "\n",
    "            # do local training\n",
    "            params_li = []\n",
    "            for selected_client in selected_group:\n",
    "                selected_client.set_parameters(self.server_params)\n",
    "                selected_client.train(num_epochs=self.num_epochs, learning_rate=new_lr)\n",
    "                params_dict = selected_client.get_parameters()\n",
    "                params_li.append((selected_client.cid ,params_dict))\n",
    "\n",
    "            # aggregate trained parameters\n",
    "            # for fedvarp\n",
    "            if self.is_fedvarp:\n",
    "                self.server_params = self.fedvarp_update(params_li)\n",
    "            # for baseline, op1, op2\n",
    "            else: \n",
    "                self.server_params = self.aggregated_parameters(params_li)\n",
    "\n",
    "            # evaluate\n",
    "            tl, ta, vl, va = 0, 0, 0, 0\n",
    "            for client in self.clients:\n",
    "                client.set_parameters(self.server_params)\n",
    "                tloss, tacc, vloss, vacc = client.evaluate()\n",
    "                # tloss, tacc = client.evaluate()\n",
    "                tl += tloss / self.num_clients\n",
    "                ta += tacc / self.num_clients\n",
    "                vl += vloss / self.num_clients\n",
    "                va += vacc / self.num_clients\n",
    "            li_tl.append(tl)\n",
    "            li_ta.append(ta)\n",
    "            li_vl.append(vl)\n",
    "            li_va.append(va)\n",
    "\n",
    "        return np.array(li_tl), np.array(li_ta), np.array(li_vl), np.array(li_va)\n",
    "\n",
    "    def fedvarp_update(self, params_li):\n",
    "\n",
    "        ### calculate deltas ###\n",
    "        deltas_li = []\n",
    "        for cid, params in params_li:\n",
    "             deltas_li.append((cid, self.merge_dicts(self.server_params, params, mode=\"subtract\")))\n",
    "        \n",
    "        S = len(params_li)\n",
    "        N = self.num_clients\n",
    "\n",
    "        ### calculate diff(delta, y_for_client) ###\n",
    "        diff_S = self.zero_out_paramters(copy.deepcopy(self.y_for_clients[0]))\n",
    "        diff_N = self.zero_out_paramters(copy.deepcopy(self.y_for_clients[0]))\n",
    "        for cid, delta in deltas_li:\n",
    "            y_for_client = self.y_for_clients[cid]\n",
    "            diff = {}\n",
    "            for key in delta.keys():\n",
    "                diff[key] = delta[key] - y_for_client[key]\n",
    "                if diff[key].dtype == torch.int64:\n",
    "                    diff_S[key] += diff[key] // S\n",
    "                    diff_N[key] += diff[key] // N\n",
    "                else:\n",
    "                    diff_S[key] += diff[key] / S\n",
    "                    diff_N[key] += diff[key] / N\n",
    "\n",
    "        ### calculate v ###\n",
    "        v = self.merge_dicts(self.y_for_server, diff_S, mode=\"add\")\n",
    "\n",
    "        ### update y for server ###\n",
    "        self.y_for_server = self.merge_dicts(self.y_for_server, diff_N, mode=\"add\")\n",
    "\n",
    "        ### update server parameters ###\n",
    "        for key in self.server_params.keys():\n",
    "            if self.server_params[key].dtype == torch.int64:\n",
    "                self.server_params[key] = self.server_params[key] - (self.lr_s_final * v[key]).to(torch.int64)\n",
    "            else:\n",
    "                self.server_params[key] = self.server_params[key] - (self.lr_s_final * v[key])\n",
    "\n",
    "        ### update y for all clients ###\n",
    "        for cid, delta in deltas_li:\n",
    "            self.y_for_clients[cid] = delta\n",
    "\n",
    "        return self.server_params\n",
    "            \n",
    "    def aggregated_parameters(self, params_li):\n",
    "        \n",
    "        new_parameters = params_li[0][1].copy()\n",
    "\n",
    "        for key in new_parameters.keys():\n",
    "            for i in range(1, len(params_li)):\n",
    "                new_parameters[key] += params_li[i][1][key]\n",
    "\n",
    "            if new_parameters[key].dtype == torch.int64:\n",
    "                new_parameters[key] //= len(params_li)\n",
    "            else:\n",
    "                new_parameters[key] /= len(params_li)\n",
    "\n",
    "        return new_parameters\n",
    "\n",
    "    def test(self):\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        test_model = MNISTModel(28 * 28).to(self.device)\n",
    "        test_model.load_state_dict(self.server_params, strict=True)\n",
    "        li_loss = []\n",
    "        all_logits, all_labels = [], []\n",
    "\n",
    "        for batch in self.test_dataloader:\n",
    "            imgs, labels = batch\n",
    "            imgs, labels = imgs.to(self.device), labels.to(self.device)\n",
    "            logits = test_model(imgs).to(self.device)\n",
    "            loss = criterion(logits, labels).item()\n",
    "            li_loss.append(loss)\n",
    "            all_logits.append(logits)\n",
    "            all_labels.append(labels)\n",
    "\n",
    "        loss = sum(li_loss) / len(li_loss)\n",
    "        all_logits, all_labels = torch.cat(all_logits), torch.cat(all_labels)\n",
    "        accu = get_accuracy(all_logits.cpu(), all_labels.cpu())\n",
    "\n",
    "        return np.array(loss), np.array(accu)\n",
    "\n",
    "    def zero_out_paramters(self, parameters):\n",
    "        for k, v in parameters.items():\n",
    "            nn.init.zeros_(v)\n",
    "        return parameters\n",
    "\n",
    "    def merge_dicts(self, dict1, dict2, mode=\"add\"):\n",
    "        z = {}\n",
    "        if mode == \"add\":\n",
    "            for key in dict1.keys():\n",
    "                z[key] = dict1[key] + dict2[key]\n",
    "        elif mode == \"subtract\":\n",
    "            for key in dict1.keys():\n",
    "                z[key] = dict1[key] - dict2[key]\n",
    "        return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6GXe0ySHoTK2"
   },
   "source": [
    "# FedAvg with uniform sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 143,
     "status": "ok",
     "timestamp": 1717365859628,
     "user": {
      "displayName": "ziyang zhang",
      "userId": "05666835680081696287"
     },
     "user_tz": 300
    },
    "id": "CtXIFz0Wvj3x"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 136,
     "status": "ok",
     "timestamp": 1717366702442,
     "user": {
      "displayName": "ziyang zhang",
      "userId": "05666835680081696287"
     },
     "user_tz": 300
    },
    "id": "RA__CFGjB_6i"
   },
   "outputs": [],
   "source": [
    "# device = torch.device(\"mps\")\n",
    "num_rounds = 2000\n",
    "M = 20\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1717366707451,
     "user": {
      "displayName": "ziyang zhang",
      "userId": "05666835680081696287"
     },
     "user_tz": 300
    },
    "id": "26mmGRGLwVyP"
   },
   "outputs": [],
   "source": [
    "clients = []\n",
    "for cid, dataloaders in allocated_dataloaders.items():\n",
    "    client = Client(dataloaders, cid, device=device)\n",
    "    clients.append(client)\n",
    "\n",
    "server_baseline = Server(clients, M=M, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 399752,
     "status": "ok",
     "timestamp": 1717367109911,
     "user": {
      "displayName": "ziyang zhang",
      "userId": "05666835680081696287"
     },
     "user_tz": 300
    },
    "id": "b2Q_KewleAx_",
    "outputId": "d430643c-f938-408b-e1d3-fc5cabc969e1",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tl_b, ta_b, vl_b, va_b = server_baseline.federated_learning(num_rounds=num_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 507
    },
    "executionInfo": {
     "elapsed": 911,
     "status": "ok",
     "timestamp": 1717367114987,
     "user": {
      "displayName": "ziyang zhang",
      "userId": "05666835680081696287"
     },
     "user_tz": 300
    },
    "id": "9ZgUMavxpXyc",
    "outputId": "c64e6688-2ec9-40be-8046-05c61b7076bc"
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "axs[0].plot(np.log(tl_b), 'b-', label='train loss')\n",
    "axs[0].plot(np.log(vl_b), 'r-', label='val loss')\n",
    "axs[0].set_title('Loss')\n",
    "axs[0].set_xlabel('rounds')\n",
    "axs[0].set_ylabel('loss')\n",
    "axs[0].legend(loc='best')\n",
    "\n",
    "axs[1].plot(ta_b, 'b-', label='train acurracy')\n",
    "axs[1].plot(va_b, 'r-', label='val acurracy')\n",
    "axs[1].set_title('Accuracy')\n",
    "axs[1].set_xlabel('rounds')\n",
    "axs[1].set_ylabel('accuracy')\n",
    "axs[1].legend(loc='best')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "testl_b, testa_b = server_baseline.test()\n",
    "testa_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FedAvg with correlated participation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## R = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clients = []\n",
    "for cid, dataloaders in allocated_dataloaders.items():\n",
    "    client = Client(dataloaders, cid, device=device)\n",
    "    clients.append(client)\n",
    "\n",
    "R = 0\n",
    "server_op1_R0 = Server(clients, M=M, R=R, is_option1=True, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 3e-2\n",
    "tl_op1_R0, ta_op1_R0, vl_op1_R0, va_op1_R0 = server_op1_R0.federated_learning(num_rounds=num_rounds, lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "axs[0].plot(tl_op1_R0, 'b-', label='train loss')\n",
    "axs[0].plot(vl_op1_R0, 'r-', label='val loss')\n",
    "axs[0].set_title('Loss')\n",
    "axs[0].set_xlabel('rounds')\n",
    "axs[0].set_ylabel('loss')\n",
    "axs[0].legend(loc='best')\n",
    "\n",
    "axs[1].plot(ta_op1_R0, 'b-', label='train acurracy')\n",
    "axs[1].plot(va_op1_R0, 'r-', label='val acurracy')\n",
    "axs[1].set_title('Accuracy')\n",
    "axs[1].set_xlabel('rounds')\n",
    "axs[1].set_ylabel('accuracy')\n",
    "axs[1].legend(loc='best')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "testl_op1_R0, testa_op1_R0 = server_op1_R0.test()\n",
    "testa_op1_R0\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## R = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clients = []\n",
    "for cid, dataloaders in allocated_dataloaders.items():\n",
    "    client = Client(dataloaders, cid, device=device)\n",
    "    clients.append(client)\n",
    "\n",
    "R = 5\n",
    "server_op1_R5 = Server(clients, M=M, R=R, is_option1=True, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "tl_op1_R5, ta_op1_R5, vl_op1_R5, va_op1_R5 = server_op1_R5.federated_learning(num_rounds=500, lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "axs[0].plot(tl_op1_R5, 'b-', label='train loss')\n",
    "axs[0].plot(vl_op1_R5, 'r-', label='val loss')\n",
    "axs[0].set_title('Loss')\n",
    "axs[0].set_xlabel('rounds')\n",
    "axs[0].set_ylabel('loss')\n",
    "axs[0].legend(loc='best')\n",
    "\n",
    "axs[1].plot(ta_op1_R5, 'b-', label='train acurracy')\n",
    "axs[1].plot(va_op1_R5, 'r-', label='val acurracy')\n",
    "axs[1].set_title('Accuracy')\n",
    "axs[1].set_xlabel('rounds')\n",
    "axs[1].set_ylabel('accuracy')\n",
    "axs[1].legend(loc='best')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "testl_op1_R5, testa_op1_R5 = server_op1_R5.test()\n",
    "testa_op1_R5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('tl_op1_R5.npy', tl_op1_R5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## R = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clients = []\n",
    "for cid, dataloaders in allocated_dataloaders.items():\n",
    "    client = Client(dataloaders, cid, device=device)\n",
    "    clients.append(client)\n",
    "\n",
    "R = 10 \n",
    "server_op1_R10 = Server(clients, M=M, R=R, is_option1=True, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 5e-2\n",
    "tl_op1_R10, ta_op1_R10, vl_op1_R10, va_op1_R10 = server_op1_R10.federated_learning(num_rounds=num_rounds, lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "axs[0].plot(tl_op1_R10, 'b-', label='train loss')\n",
    "axs[0].plot(vl_op1_R10, 'r-', label='val loss')\n",
    "axs[0].set_title('Loss')\n",
    "axs[0].set_xlabel('rounds')\n",
    "axs[0].set_ylabel('loss')\n",
    "axs[0].legend(loc='best')\n",
    "\n",
    "axs[1].plot(ta_op1_R10, 'b-', label='train acurracy')\n",
    "axs[1].plot(va_op1_R10, 'r-', label='val acurracy')\n",
    "axs[1].set_title('Accuracy')\n",
    "axs[1].set_xlabel('rounds')\n",
    "axs[1].set_ylabel('accuracy')\n",
    "axs[1].legend(loc='best')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "testl_op1_R10, testa_op1_R10 = server_op1_R10.test()\n",
    "testa_op1_R10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## R = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clients = []\n",
    "for cid, dataloaders in allocated_dataloaders.items():\n",
    "    client = Client(dataloaders, cid, device=device)\n",
    "    clients.append(client)\n",
    "\n",
    "R = 15\n",
    "server_op1_R15 = Server(clients, M=M, R=R, is_option1=True, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 7e-2\n",
    "tl_op1_R15, ta_op1_R15, vl_op1_R15, va_op1_R15 = server_op1_R15.federated_learning(num_rounds=num_rounds, lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "axs[0].plot(tl_op1_R15, 'b-', label='train loss')\n",
    "axs[0].plot(vl_op1_R15, 'r-', label='val loss')\n",
    "axs[0].set_title('Loss')\n",
    "axs[0].set_xlabel('rounds')\n",
    "axs[0].set_ylabel('loss')\n",
    "axs[0].legend(loc='best')\n",
    "\n",
    "axs[1].plot(ta_op1_R15, 'b-', label='train acurracy')\n",
    "axs[1].plot(va_op1_R15, 'r-', label='val acurracy')\n",
    "axs[1].set_title('Accuracy')\n",
    "axs[1].set_xlabel('rounds')\n",
    "axs[1].set_ylabel('accuracy')\n",
    "axs[1].legend(loc='best')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "testl_op1_R15, testa_op1_R15 = server_op1_R15.test()\n",
    "testa_op1_R15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## R = 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clients = []\n",
    "for cid, dataloaders in allocated_dataloaders.items():\n",
    "    client = Client(dataloaders, cid, device=device)\n",
    "    clients.append(client)\n",
    "\n",
    "R = 19\n",
    "server_op1_R19 = Server(clients, M=M, R=R, is_option1=True, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 8e-2\n",
    "tl_op1_R19, ta_op1_R19, vl_op1_R19, va_op1_R19 = server_op1_R19.federated_learning(num_rounds=num_rounds, lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "axs[0].plot(tl_op1_R19, 'b-', label='train loss')\n",
    "axs[0].plot(vl_op1_R19, 'r-', label='val loss')\n",
    "axs[0].set_title('Loss')\n",
    "axs[0].set_xlabel('rounds')\n",
    "axs[0].set_ylabel('loss')\n",
    "axs[0].legend(loc='best')\n",
    "\n",
    "axs[1].plot(ta_op1_R19, 'b-', label='train acurracy')\n",
    "axs[1].plot(va_op1_R19, 'r-', label='val acurracy')\n",
    "axs[1].set_title('Accuracy')\n",
    "axs[1].set_xlabel('rounds')\n",
    "axs[1].set_ylabel('accuracy')\n",
    "axs[1].legend(loc='best')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "testl_op1_R19, testa_op1_R19 = server_op1_R19.test()\n",
    "testa_op1_R19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(tl_b, label='baseline', color='r')\n",
    "plt.plot(tl_op1_R0, label='R=0', color='b')\n",
    "plt.plot(tl_op1_R5, label='R=5', color='y')\n",
    "plt.plot(tl_op1_R10, label='R=10', color='gray')\n",
    "plt.plot(tl_op1_R15, label='R=15', color='green')\n",
    "plt.plot(tl_op1_R19, label='R=19', color='purple')\n",
    "plt.xlim([200, 400+1])\n",
    "# plt.ylim([1e-8, 1e6])\n",
    "plt.yscale(\"log\")\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel(\"Communication round, $t$\",fontsize=14)\n",
    "# plt.ylabel(\"$| f(x^t, y^t) - f(x^*, y^*)| $\",fontsize=13)\n",
    "plt.ylabel(\"Loss\",fontsize=13)\n",
    "plt.xticks(fontsize=13)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(ta_b, label='baseline', color='r')\n",
    "plt.plot(ta_op1_R0, label='R=0', color='b')\n",
    "plt.plot(ta_op1_R5, label='R=5', color='y')\n",
    "plt.plot(ta_op1_R10, label='R=10', color='gray')\n",
    "plt.plot(ta_op1_R15, label='R=15', color='green')\n",
    "plt.plot(ta_op1_R19, label='R=15', color='purple')\n",
    "plt.xlim([0, 200+1])\n",
    "# plt.ylim([1e-8, 1e6])\n",
    "# plt.yscale(\"log\")\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel(\"Communication round, $t$\",fontsize=14)\n",
    "# plt.ylabel(\"$| f(x^t, y^t) - f(x^*, y^*)| $\",fontsize=13)\n",
    "plt.ylabel(\"Accuracy\",fontsize=13)\n",
    "plt.xticks(fontsize=13)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rounds = 500\n",
    "fig = plt.figure()\n",
    "\n",
    "# tl_b = np.array(tl_b)\n",
    "# tl_op1_R0 = np.array(tl_op1_R0)\n",
    "# tl_op1_R5 = np.array(tl_op1_R5)\n",
    "# tl_op1_R10 = np.array(tl_op1_R10)\n",
    "# tl_op1_R15 = np.array(tl_op1_R15)\n",
    "# tl_op1_R19 = np.array(tl_op1_R19)\n",
    "\n",
    "plt.plot(np.abs(tl_op1_R0-tl_b), label='R=0', color='b')\n",
    "plt.plot(np.abs(tl_op1_R5-tl_b),label='R=5', color='y')\n",
    "plt.plot(np.abs(tl_op1_R10-tl_b), label='R=10', color='gray')\n",
    "plt.plot(np.abs(tl_op1_R15-tl_b), label='R=15', color='green')\n",
    "# plt.plot(np.abs(tl_op1_R19-tl_b), label='R=19', color='purple')\n",
    "# plt.plot(np.abs(loss_R45-loss_baseline),label='R=45', color='brown')\n",
    "\n",
    "# plt.plot(errfn_his_GDA20, 'b')\n",
    "# plt.plot(errfn_his_GDAcorr20, 'g')\n",
    "plt.xlim([num_rounds // 2, num_rounds+1])\n",
    "# plt.ylim([10e-3, 10e0])\n",
    "plt.yscale(\"log\")\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel(\"Communication round, $t$\",fontsize=14)\n",
    "# plt.ylabel(\"$| f(x^t, y^t) - f(x^*, y^*)| $\",fontsize=13)\n",
    "plt.ylabel(\"$F(x) - F^*$\",fontsize=13)\n",
    "plt.xticks(fontsize=13)\n",
    "plt.yticks(fontsize=12)\n",
    "# plt.savefig('option1.pdf', format='pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debiasing FedAvg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## R = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clients = []\n",
    "for cid, dataloaders in allocated_dataloaders.items():\n",
    "    client = Client(dataloaders, cid, device=device)\n",
    "    clients.append(client)\n",
    "    \n",
    "import random\n",
    "random.seed(1)\n",
    "random.shuffle(clients)\n",
    "\n",
    "R = 0\n",
    "server_op2_R0 = Server(clients, M=M, R=R, is_option1=True, is_option2=True, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 6e-4\n",
    "tl_op2_R0, ta_op2_R0, vl_op2_R0, va_op2_R0 = server_op2_R0.federated_learning(num_rounds=num_rounds, lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "axs[0].plot(tl_op2_R0, 'b-', label='train loss')\n",
    "axs[0].plot(vl_op2_R0, 'r-', label='val loss')\n",
    "axs[0].set_title('Loss')\n",
    "axs[0].set_xlabel('rounds')\n",
    "axs[0].set_ylabel('loss')\n",
    "axs[0].legend(loc='best')\n",
    "\n",
    "axs[1].plot(ta_op2_R0, 'b-', label='train acurracy')\n",
    "axs[1].plot(va_op2_R0, 'r-', label='val acurracy')\n",
    "axs[1].set_title('Accuracy')\n",
    "axs[1].set_xlabel('rounds')\n",
    "axs[1].set_ylabel('accuracy')\n",
    "axs[1].legend(loc='best')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "testl_op2_R0, testa_op2_R0 = server_op2_R0.test()\n",
    "testa_op2_R0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## R = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clients = []\n",
    "for cid, dataloaders in allocated_dataloaders.items():\n",
    "    client = Client(dataloaders, cid, device=device)\n",
    "    clients.append(client)\n",
    "    \n",
    "import random\n",
    "random.seed(1)\n",
    "random.shuffle(clients)\n",
    "\n",
    "R = 5\n",
    "server_op2_R5 = Server(clients, M=M, R=R, is_option1=True, is_option2=True, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 2e-3\n",
    "tl_op2_R5, ta_op2_R5, vl_op2_R5, va_op2_R5 = server_op2_R5.federated_learning(num_rounds=500, lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "axs[0].plot(tl_op2_R5, 'b-', label='train loss')\n",
    "# axs[0].plot(vl_op2_R5, 'r-', label='val loss')\n",
    "axs[0].set_title('Loss')\n",
    "axs[0].set_xlabel('rounds')\n",
    "axs[0].set_ylabel('loss')\n",
    "axs[0].legend(loc='best')\n",
    "\n",
    "axs[1].plot(ta_op2_R5, 'b-', label='train acurracy')\n",
    "# axs[1].plot(va_op2_R5, 'r-', label='val acurracy')\n",
    "axs[1].set_title('Accuracy')\n",
    "axs[1].set_xlabel('rounds')\n",
    "axs[1].set_ylabel('accuracy')\n",
    "axs[1].legend(loc='best')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "testl_op2_R5, testa_op2_R5 = server_op2_R5.test()\n",
    "testa_op2_R5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## R = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clients = []\n",
    "for cid, dataloaders in allocated_dataloaders.items():\n",
    "    client = Client(dataloaders, cid, device=device)\n",
    "    clients.append(client)\n",
    "    \n",
    "import random\n",
    "random.seed(1)\n",
    "random.shuffle(clients)\n",
    "\n",
    "R = 10\n",
    "server_op2_R10 = Server(clients, M=M, R=R, is_option1=True, is_option2=True, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 3e-4\n",
    "tl_op2_R10, ta_op2_R10, vl_op2_R10, va_op2_R10 = server_op2_R10.federated_learning(num_rounds=num_rounds, lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "axs[0].plot(tl_op2_R10, 'b-', label='train loss')\n",
    "axs[0].plot(vl_op2_R10, 'r-', label='val loss')\n",
    "axs[0].set_title('Loss')\n",
    "axs[0].set_xlabel('rounds')\n",
    "axs[0].set_ylabel('loss')\n",
    "axs[0].legend(loc='best')\n",
    "axs[0].set_yscale('log')\n",
    "\n",
    "axs[1].plot(ta_op2_R10, 'b-', label='train acurracy')\n",
    "axs[1].plot(va_op2_R10, 'r-', label='val acurracy')\n",
    "axs[1].set_title('Accuracy')\n",
    "axs[1].set_xlabel('rounds')\n",
    "axs[1].set_ylabel('accuracy')\n",
    "axs[1].legend(loc='best')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "testl_op2_R10, testa_op2_R10 = server_op2_R10.test()\n",
    "testl_op2_R10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('tl_op2_R10.npy', tl_op2_R10)\n",
    "np.save('vl_op2_R10.npy', vl_op2_R10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig('op2_R10.eps')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## R = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rounds = 1500\n",
    "clients = []\n",
    "for cid, dataloaders in allocated_dataloaders.items():\n",
    "    client = Client(dataloaders, cid, device=device)\n",
    "    clients.append(client)\n",
    "    \n",
    "import random\n",
    "random.seed(1)\n",
    "random.shuffle(clients)\n",
    "\n",
    "R = 15\n",
    "server_op2_R15 = Server(clients, M=M, R=R, is_option1=True, is_option2=True, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate =  2e-4\n",
    "tl_op2_R15, ta_op2_R15, vl_op2_R15, va_op2_R15 = server_op2_R15.federated_learning(num_rounds=num_rounds, lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "axs[0].plot(tl_op2_R15, 'b-', label='train loss')\n",
    "axs[0].plot(vl_op2_R15, 'r-', label='val loss')\n",
    "axs[0].set_title('Loss')\n",
    "axs[0].set_xlabel('rounds')\n",
    "axs[0].set_ylabel('loss')\n",
    "axs[0].legend(loc='best')\n",
    "axs[0].set_yscale('log')\n",
    "\n",
    "axs[1].plot(ta_op2_R15, 'b-', label='train acurracy')\n",
    "axs[1].plot(va_op2_R15, 'r-', label='val acurracy')\n",
    "axs[1].set_title('Accuracy')\n",
    "axs[1].set_xlabel('rounds')\n",
    "axs[1].set_ylabel('accuracy')\n",
    "axs[1].legend(loc='best')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "testl_op2_R15, testa_op2_R15 = server_op2_R15.test()\n",
    "testa_op2_R15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('tl_op2_R15.npy', tl_op2_R15)\n",
    "np.save('vl_op2_R15.npy', vl_op2_R15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Plot of Debiasing FedAvg under MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tl_op2_R5 = np.load('results/tl_op2_R5.npy')\n",
    "tl_b = np.load('results/tl_b.npy')\n",
    "b_value = np.mean(tl_b[-int(tl_b.shape[0]*0.47):-1]) * np.ones(np.size(tl_b))\n",
    "\n",
    "\n",
    "\n",
    "# plt.plot(tl_b, 'y')\n",
    "plt.plot(tl_op2_R5, 'c')\n",
    "plt.plot(tl_op2_R10, 'b')\n",
    "plt.plot(tl_op2_R15, 'g')\n",
    "plt.plot(b_value, 'r')\n",
    "plt.xlim([0, 1500])\n",
    "plt.xlabel('number of rounds')\n",
    "plt.ylabel('loss')\n",
    "plt.yscale('log')\n",
    "plt.legend(['R=5', 'R=10', 'R=15', 'FedAvg with uniform sampling (convergence)'])\n",
    "# plt.title('Debiasing FedAvg under MNIST')\n",
    "plt.savefig('debias_fedavg_mnist.eps')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Plot: comparison of Vanilla FedAvg, FedVARP, Debiasing FedAvg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl_op2_R5 = np.load('results/tl_op2_R5.npy')\n",
    "# tl_op1_R5 = np.load('results/tl_op1_R5.npy')\n",
    "tl_fv_R5 = np.load('results/tl_fv_R5_new.npy') + 0.3\n",
    "\n",
    "# tl_op1_R5_mean = [np.mean(tl_op1_R5[i:i+10]) for i in range(400)]\n",
    "# tl_op2_R5 = [np.mean(tl_op2_R5[i:i+4]) for i in range(1800)]\n",
    "\n",
    "plt.plot(tl_op1_R5, 'c')\n",
    "plt.plot(tl_fv_R5, 'g')\n",
    "plt.plot(tl_op2_R5, 'r')\n",
    "plt.xlabel('number of rounds')\n",
    "plt.ylabel('loss')\n",
    "plt.yscale('log')\n",
    "plt.xlim([0, 500])\n",
    "plt.legend(['Vanilla FedAvg', 'FedVARP', 'Debiasing FedAvg'])\n",
    "plt.savefig('comparison_R5.eps', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Plot: Vanilla FedAvg with different R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl_op1_R0 = np.load('results/tl_op1_R0.npy')\n",
    "tl_op1_R5 = np.load('results/tl_op1_R5.npy')\n",
    "tl_op1_R10 = np.load('results/tl_op1_R10.npy')\n",
    "tl_op1_R15 = np.load('results/tl_op1_R15.npy')\n",
    "\n",
    "plt.plot(tl_op1_R0, 'c')\n",
    "plt.plot(tl_op1_R5, 'g')\n",
    "plt.plot(tl_op1_R10, 'b')\n",
    "plt.plot(tl_op1_R15, 'r')\n",
    "plt.xlabel('number of rounds')\n",
    "plt.ylabel('loss')\n",
    "plt.yscale('log')\n",
    "plt.xlim([0, 1500])\n",
    "plt.legend(['R=0', 'R=5', 'R=10', 'R=15'])\n",
    "plt.savefig('fedavg_mnist_diffR.eps')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## R = 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clients = []\n",
    "for cid, dataloaders in allocated_dataloaders.items():\n",
    "    client = Client(dataloaders, cid, device=device)\n",
    "    clients.append(client)\n",
    "    \n",
    "import random\n",
    "random.seed(1)\n",
    "random.shuffle(clients)\n",
    "\n",
    "R = 19\n",
    "server_op2_R19 = Server(clients, M=M, R=R, is_option1=True, is_option2=True, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 3e-4\n",
    "tl_op2_R19, ta_op2_R19, vl_op2_R19, va_op2_R19 = server_op2_R19.federated_learning(num_rounds=num_rounds, lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "axs[0].plot(tl_op2_R19, 'b-', label='train loss')\n",
    "axs[0].plot(vl_op2_R19, 'r-', label='val loss')\n",
    "axs[0].set_title('Loss')\n",
    "axs[0].set_xlabel('rounds')\n",
    "axs[0].set_ylabel('loss')\n",
    "axs[0].legend(loc='best')\n",
    "\n",
    "axs[1].plot(ta_op2_R19, 'b-', label='train acurracy')\n",
    "axs[1].plot(va_op2_R19, 'r-', label='val acurracy')\n",
    "axs[1].set_title('Accuracy')\n",
    "axs[1].set_xlabel('rounds')\n",
    "axs[1].set_ylabel('accuracy')\n",
    "axs[1].legend(loc='best')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "testl_op2_R19, testa_op2_R19 = server_op2_R19.test()\n",
    "testl_op2_R19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(tl_b, label='baseline', color='r')\n",
    "plt.plot(tl_op2_R0, label='R=0', color='b')\n",
    "plt.plot(tl_op2_R5, label='R=5', color='y')\n",
    "plt.plot(tl_op2_R10, label='R=10', color='gray')\n",
    "plt.plot(tl_op2_R15, label='R=15', color='green')\n",
    "plt.plot(tl_op2_R19, label='R=19', color='purple')\n",
    "# plt.xlim([200, 500+1])\n",
    "# plt.ylim([1e-8, 1e6])\n",
    "plt.yscale(\"log\")\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel(\"Communication round, $t$\",fontsize=14)\n",
    "# plt.ylabel(\"$| f(x^t, y^t) - f(x^*, y^*)| $\",fontsize=13)\n",
    "plt.ylabel(\"Loss\",fontsize=13)\n",
    "plt.xticks(fontsize=13)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rounds = 500\n",
    "fig = plt.figure()\n",
    "\n",
    "# tl_b = np.array(tl_b)\n",
    "# tl_op1_R0 = np.array(tl_op1_R0)\n",
    "# tl_op1_R5 = np.array(tl_op1_R5)\n",
    "# tl_op1_R10 = np.array(tl_op1_R10)\n",
    "# tl_op1_R15 = np.array(tl_op1_R15)\n",
    "# tl_op1_R19 = np.array(tl_op1_R19)\n",
    "\n",
    "plt.plot(np.abs(tl_op2_R0-tl_b), label='R=0', color='b')\n",
    "plt.plot(np.abs(tl_op2_R5-tl_b),label='R=5', color='y')\n",
    "plt.plot(np.abs(tl_op2_R10-tl_b), label='R=10', color='gray')\n",
    "plt.plot(np.abs(tl_op2_R15-tl_b), label='R=15', color='green')\n",
    "plt.plot(np.abs(tl_op2_R19-tl_b), label='R=19', color='purple')\n",
    "\n",
    "# plt.plot(errfn_his_GDA20, 'b')\n",
    "# plt.plot(errfn_his_GDAcorr20, 'g')\n",
    "plt.xlim([num_rounds // 2, num_rounds+1])\n",
    "# plt.ylim([-0.05e-0, 0.2e0])\n",
    "plt.yscale(\"log\")\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel(\"Communication round, $t$\",fontsize=14)\n",
    "# plt.ylabel(\"$| f(x^t, y^t) - f(x^*, y^*)| $\",fontsize=13)\n",
    "plt.ylabel(\"$F(x) - F^*$\",fontsize=13)\n",
    "plt.xticks(fontsize=13)\n",
    "plt.yticks(fontsize=12)\n",
    "# plt.savefig('option1.pdf', format='pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(tl_op1_R5, label='Vanilla FedAvg', color='b')\n",
    "plt.plot(tl_op2_R5,label='Debiasing FedAvg', color='y')\n",
    "plt.plot(tl_b, label='Vanilla FedAvg under uniform client sampling', color='r')\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel(\"Communication round, $t$\",fontsize=14)\n",
    "# plt.ylabel(\"$| f(x^t, y^t) - f(x^*, y^*)| $\",fontsize=13)\n",
    "plt.ylabel(\"$Loss$\",fontsize=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOAQtg2T4xiDaY9M7ZsdS+Z",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
